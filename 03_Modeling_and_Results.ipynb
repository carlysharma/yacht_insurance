{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yacht Insurance Claims Data \n",
    "##### NOTEBOOK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement:** What is the likelihood that a yacht insurance policy has at least 1 claim within five years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Import libraries and read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNetCV, LogisticRegressionCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years Exp.</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Length</th>\n",
       "      <th>Hull Limit</th>\n",
       "      <th># Engines</th>\n",
       "      <th>num_claims</th>\n",
       "      <th>Age</th>\n",
       "      <th>policy_length</th>\n",
       "      <th>New/Renl/Endt/Canc/Flat_endt</th>\n",
       "      <th>New/Renl/Endt/Canc/Flat_endt-canc</th>\n",
       "      <th>...</th>\n",
       "      <th>Mooring County_sarasota</th>\n",
       "      <th>Mooring County_sinaloa</th>\n",
       "      <th>Mooring County_skagit</th>\n",
       "      <th>Mooring County_sonora</th>\n",
       "      <th>Mooring County_south pacific</th>\n",
       "      <th>Mooring County_st. johns</th>\n",
       "      <th>Mooring County_st. lucie</th>\n",
       "      <th>Mooring County_ventura</th>\n",
       "      <th>Mooring County_volusia</th>\n",
       "      <th>Mooring County_whatcom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1275000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years Exp.  Year Built  Length  Hull Limit  # Engines  num_claims  Age  \\\n",
       "0         2.0      1997.0    63.0    500000.0        2.0         0.0   73   \n",
       "1        22.0      2006.0    61.0   1275000.0        2.0         0.0   69   \n",
       "2        30.0      2001.0    48.0    400000.0        2.0         0.0   78   \n",
       "3        20.0      1973.0    32.0     35000.0        0.0         0.0   44   \n",
       "4        30.0      1989.0    43.0    200000.0        1.0         0.0   70   \n",
       "\n",
       "   policy_length  New/Renl/Endt/Canc/Flat_endt  \\\n",
       "0         1758.0                             0   \n",
       "1         1771.0                             0   \n",
       "2         1759.0                             0   \n",
       "3         1759.0                             0   \n",
       "4         1756.0                             0   \n",
       "\n",
       "   New/Renl/Endt/Canc/Flat_endt-canc  ...  Mooring County_sarasota  \\\n",
       "0                                  0  ...                        0   \n",
       "1                                  0  ...                        0   \n",
       "2                                  0  ...                        0   \n",
       "3                                  0  ...                        0   \n",
       "4                                  0  ...                        0   \n",
       "\n",
       "   Mooring County_sinaloa  Mooring County_skagit  Mooring County_sonora  \\\n",
       "0                       0                      0                      0   \n",
       "1                       0                      0                      0   \n",
       "2                       0                      0                      0   \n",
       "3                       0                      0                      0   \n",
       "4                       0                      0                      0   \n",
       "\n",
       "   Mooring County_south pacific  Mooring County_st. johns  \\\n",
       "0                             0                         0   \n",
       "1                             0                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "\n",
       "   Mooring County_st. lucie  Mooring County_ventura  Mooring County_volusia  \\\n",
       "0                         0                       0                       0   \n",
       "1                         0                       0                       0   \n",
       "2                         0                       0                       0   \n",
       "3                         0                       0                       0   \n",
       "4                         0                       0                       0   \n",
       "\n",
       "   Mooring County_whatcom  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.read_csv('../datasets/combined2.csv')\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING: Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BELOW:** Initially we wanted to see if we could do a multiclass classification model to predict whether a boat might have 0, 1, 2, or 3 claims. Unfortunately, with so few examples for our models to train on for 2 or 3 claims, we decided to move forward with just binary (having 0 or at least 1 claim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish a baseline\n",
    "\n",
    "0 claims = 92%<br>\n",
    "1 claim = 6.6%<br>\n",
    "2 claims = 1%<br>\n",
    "3 claims = 0.2%<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5836\n",
       "1.0     421\n",
       "2.0      68\n",
       "3.0      15\n",
       "Name: num_claims, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['num_claims'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.920505\n",
       "1.0    0.066404\n",
       "2.0    0.010726\n",
       "3.0    0.002366\n",
       "Name: num_claims, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['num_claims'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "6335    0\n",
       "6336    0\n",
       "6337    0\n",
       "6338    0\n",
       "6339    0\n",
       "Name: num_claims, Length: 6340, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['num_claims'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined.drop(columns=['num_claims'])\n",
    "y = combined['num_claims']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 MODELS: KNN, Logistic Regression, Random Forest, Extra Trees\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and fit 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_sc, y_train)\n",
    "knn_pred = knn.predict(X_test_sc)\n",
    "\n",
    "lr = LogisticRegression(max_iter=500,random_state=42)\n",
    "lr.fit(X_train_sc, y_train)\n",
    "lr_pred = lr.predict(X_test_sc)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf.fit(X_train_sc, y_train)\n",
    "rf_pred = rf.predict(X_test_sc)\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=100,random_state=42)\n",
    "et.fit(X_train_sc, y_train)\n",
    "et_pred = et.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.927     0.987     0.956      1167\n",
      "         1.0      0.278     0.060     0.098        84\n",
      "         2.0      0.400     0.143     0.211        14\n",
      "         3.0      1.000     0.667     0.800         3\n",
      "\n",
      "    accuracy                          0.916      1268\n",
      "   macro avg      0.651     0.464     0.516      1268\n",
      "weighted avg      0.878     0.916     0.891      1268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.923     1.000     0.960      1167\n",
      "         1.0      0.000     0.000     0.000        84\n",
      "         2.0      0.000     0.000     0.000        14\n",
      "         3.0      1.000     1.000     1.000         3\n",
      "\n",
      "    accuracy                          0.923      1268\n",
      "   macro avg      0.481     0.500     0.490      1268\n",
      "weighted avg      0.852     0.923     0.886      1268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlychamberlain/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.939     0.995     0.966      1167\n",
      "         1.0      0.600     0.107     0.182        84\n",
      "         2.0      1.000     1.000     1.000        14\n",
      "         3.0      1.000     1.000     1.000         3\n",
      "\n",
      "    accuracy                          0.936      1268\n",
      "   macro avg      0.885     0.776     0.787      1268\n",
      "weighted avg      0.918     0.936     0.915      1268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.942     0.985     0.963      1167\n",
      "         1.0      0.429     0.143     0.214        84\n",
      "         2.0      0.875     1.000     0.933        14\n",
      "         3.0      1.000     1.000     1.000         3\n",
      "\n",
      "    accuracy                          0.930      1268\n",
      "   macro avg      0.811     0.782     0.778      1268\n",
      "weighted avg      0.907     0.930     0.913      1268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, et_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Looking at these scores we can tell that the model is overfitting to 2 and 3 claims. The models are very good at identifying these minority classes but that's because "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MODELING: Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up for all models**<br>\n",
    "1. Create binary class column<br>\n",
    "2. Define X, y<br>\n",
    "3. Scale X, y<br>\n",
    "4. Train, test, split<br>\n",
    "\n",
    "**Normal Modeling**<br>\n",
    "1. Test models (KNN, Random Forest,  ExtraTrees, Logistic Regression, LinearSVM)<br>\n",
    "2. Get micro-f1 scores for each model and add to a table to compare<br>\n",
    "\n",
    "**With OverSampling**<br>\n",
    "1. Instantiate RandomOverSampler<br>\n",
    "2. Fit training data on oversampler<br>\n",
    "3. Test same models w/ same parameters<br>\n",
    "4. Get f1 scores and add to a table to compare<br>\n",
    "\n",
    "**With OverSampling and Undersampling**<br>\n",
    "1. Instantiate RandomOverSampler, fit.\n",
    "2. Instantiate UnderOverSampler, fit.\n",
    "3. Test same models w/ same parameters<br>\n",
    "4. Get f1 scores and add to a table to compare<br>\n",
    "\n",
    "**With SMOTE**<br>\n",
    "1. Instantiate SMOTE, fit.<br>\n",
    "2. Test same models w/ same parameters<br>\n",
    "3. Get f1 scores and add to a table to compare<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BINARY CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish a baseline\n",
    "\n",
    "0 claims = 92%<br>\n",
    "At least 1 claim = 7.9%<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accuracy, Recall, Weighted F1 Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_scores = pd.DataFrame(columns=['Accuracy', 'Recall','Weighted F1 Score'])\n",
    "binary_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.920505\n",
       "1    0.079495\n",
       "Name: binary, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['binary'] = [1 if x > 0 else 0 for x in combined['num_claims']]\n",
    "combined['binary'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined.drop(columns=['num_claims','binary'])\n",
    "y = combined['binary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 BASIC MODELS: KNN, Logistic Regression, Random Forest, Extra Trees\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_sc, y_train)\n",
    "knn_pred = knn.predict(X_test_sc)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_sc, y_train)\n",
    "lr_pred = lr.predict(X_test_sc)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf.fit(X_train_sc, y_train)\n",
    "rf_pred = rf.predict(X_test_sc)\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=100,random_state=42)\n",
    "et.fit(X_train_sc, y_train)\n",
    "et_pred = et.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('KNN Results')\n",
    "# print(accuracy_score(y_test, knn_pred))\n",
    "# print(recall_score(y_test, knn_pred))\n",
    "# print(f1_score(y_test, knn_pred ,average='weighted'))\n",
    "# print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN(plain)</th>\n",
       "      <td>0.911672</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.892369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(plain)</th>\n",
       "      <td>0.919558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(plain)</th>\n",
       "      <td>0.934543</td>\n",
       "      <td>0.227723</td>\n",
       "      <td>0.917014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(plain)</th>\n",
       "      <td>0.926656</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.911725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy    Recall  Weighted F1 Score\n",
       "KNN(plain)  0.911672  0.128713           0.892369\n",
       "LR(plain)   0.919558  0.000000           0.881779\n",
       "RF(plain)   0.934543  0.227723           0.917014\n",
       "ET(plain)   0.926656  0.237624           0.911725"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_knn = pd.Series(data=[accuracy_score(y_test, knn_pred), recall_score(y_test, knn_pred),\n",
    "                              f1_score(y_test, knn_pred ,average='weighted')], index=binary_scores.columns, name = 'KNN(plain)')\n",
    "\n",
    "regular_lr = pd.Series(data=[accuracy_score(y_test, lr_pred), recall_score(y_test, lr_pred),\n",
    "                              f1_score(y_test, lr_pred ,average='weighted')], index=binary_scores.columns, name = 'LR(plain)')\n",
    "\n",
    "regular_rf = pd.Series(data=[accuracy_score(y_test, rf_pred), recall_score(y_test, rf_pred),\n",
    "                              f1_score(y_test, rf_pred ,average='weighted')], index=binary_scores.columns, name = 'RF(plain)')\n",
    "\n",
    "regular_et = pd.Series(data=[accuracy_score(y_test, et_pred), recall_score(y_test, et_pred),\n",
    "                              f1_score(y_test, et_pred ,average='weighted')], index=binary_scores.columns, name = 'ET(plain)')\n",
    "\n",
    "binary_scores = binary_scores.append([regular_knn, regular_lr, regular_rf, regular_et])\n",
    "\n",
    "binary_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH OVERSAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the imbalance of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4669, 1: 403})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://beckernick.github.io/oversampling-modeling/\n",
    "\n",
    "over = RandomOverSampler(sampling_strategy=0.2, random_state=42)\n",
    "X_over, y_over = over.fit_resample(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4669, 1: 933})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_counter = Counter(y_over)\n",
    "over_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_over, y_over)\n",
    "knn_pred = knn.predict(X_test_sc)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_over, y_over)\n",
    "lr_pred = lr.predict(X_test_sc)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf.fit(X_over, y_over)\n",
    "rf_pred = rf.predict(X_test_sc)\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=100,random_state=42)\n",
    "et.fit(X_over, y_over)\n",
    "et_pred = et.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN(plain)</th>\n",
       "      <td>0.911672</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.892369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(plain)</th>\n",
       "      <td>0.919558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(plain)</th>\n",
       "      <td>0.934543</td>\n",
       "      <td>0.227723</td>\n",
       "      <td>0.917014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(plain)</th>\n",
       "      <td>0.926656</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.911725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN(oversample)</th>\n",
       "      <td>0.864353</td>\n",
       "      <td>0.346535</td>\n",
       "      <td>0.874381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(oversample)</th>\n",
       "      <td>0.897476</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.877101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(oversample)</th>\n",
       "      <td>0.932965</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.917971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(oversample)</th>\n",
       "      <td>0.925868</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.911837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Accuracy    Recall  Weighted F1 Score\n",
       "KNN(plain)       0.911672  0.128713           0.892369\n",
       "LR(plain)        0.919558  0.000000           0.881779\n",
       "RF(plain)        0.934543  0.227723           0.917014\n",
       "ET(plain)        0.926656  0.237624           0.911725\n",
       "KNN(oversample)  0.864353  0.346535           0.874381\n",
       "LR(oversample)   0.897476  0.059406           0.877101\n",
       "RF(oversample)   0.932965  0.257426           0.917971\n",
       "ET(oversample)   0.925868  0.247525           0.911837"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_knn = pd.Series(data=[accuracy_score(y_test, knn_pred), recall_score(y_test, knn_pred),\n",
    "                              f1_score(y_test, knn_pred ,average='weighted')], index=binary_scores.columns, name = 'KNN(oversample)')\n",
    "\n",
    "over_lr = pd.Series(data=[accuracy_score(y_test, lr_pred), recall_score(y_test, lr_pred),\n",
    "                              f1_score(y_test, lr_pred ,average='weighted')], index=binary_scores.columns, name = 'LR(oversample)')\n",
    "\n",
    "over_rf = pd.Series(data=[accuracy_score(y_test, rf_pred), recall_score(y_test, rf_pred),\n",
    "                              f1_score(y_test, rf_pred ,average='weighted')], index=binary_scores.columns, name = 'RF(oversample)')\n",
    "\n",
    "over_et = pd.Series(data=[accuracy_score(y_test, et_pred), recall_score(y_test, et_pred),\n",
    "                              f1_score(y_test, et_pred ,average='weighted')], index=binary_scores.columns, name = 'ET(oversample)')\n",
    "\n",
    "binary_scores = binary_scores.append([over_knn, over_lr, over_rf, over_et])\n",
    "\n",
    "binary_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SMOTE Oversampling and Random Under Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a pipeline with SMOTE and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://pypi.org/project/imbalanced-learn/\n",
    "# ref: https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.1,random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5,random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm_und, y_sm_und = pipeline.fit_resample(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 932, 1: 466})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_5 = Counter(y_sm_und)\n",
    "counter_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_sm_und, y_sm_und)\n",
    "knn_pred = knn.predict(X_test_sc)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_sm_und, y_sm_und)\n",
    "lr_pred = lr.predict(X_test_sc)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf.fit(X_sm_und, y_sm_und)\n",
    "rf_pred = rf.predict(X_test_sc)\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=100,random_state=42)\n",
    "et.fit(X_sm_und, y_sm_und)\n",
    "et_pred = et.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN(plain)</th>\n",
       "      <td>0.911672</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.892369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(plain)</th>\n",
       "      <td>0.919558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(plain)</th>\n",
       "      <td>0.934543</td>\n",
       "      <td>0.227723</td>\n",
       "      <td>0.917014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(plain)</th>\n",
       "      <td>0.926656</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.911725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN(oversample)</th>\n",
       "      <td>0.864353</td>\n",
       "      <td>0.346535</td>\n",
       "      <td>0.874381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(oversample)</th>\n",
       "      <td>0.897476</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.877101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(oversample)</th>\n",
       "      <td>0.932965</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.917971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(oversample)</th>\n",
       "      <td>0.925868</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.911837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN(SMOTE/Under)</th>\n",
       "      <td>0.766562</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.810732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(SMOTE/Under)</th>\n",
       "      <td>0.803628</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.832253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(LR(SMOTE/Under))</th>\n",
       "      <td>0.898265</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.901056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(LR(SMOTE/Under))</th>\n",
       "      <td>0.865931</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.876633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy    Recall  Weighted F1 Score\n",
       "KNN(plain)           0.911672  0.128713           0.892369\n",
       "LR(plain)            0.919558  0.000000           0.881779\n",
       "RF(plain)            0.934543  0.227723           0.917014\n",
       "ET(plain)            0.926656  0.237624           0.911725\n",
       "KNN(oversample)      0.864353  0.346535           0.874381\n",
       "LR(oversample)       0.897476  0.059406           0.877101\n",
       "RF(oversample)       0.932965  0.257426           0.917971\n",
       "ET(oversample)       0.925868  0.247525           0.911837\n",
       "KNN(SMOTE/Under)     0.766562  0.376238           0.810732\n",
       "LR(SMOTE/Under)      0.803628  0.277228           0.832253\n",
       "RF(LR(SMOTE/Under))  0.898265  0.425743           0.901056\n",
       "ET(LR(SMOTE/Under))  0.865931  0.376238           0.876633"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_knn = pd.Series(data=[accuracy_score(y_test, knn_pred), recall_score(y_test, knn_pred),\n",
    "                              f1_score(y_test, knn_pred ,average='weighted')], index=binary_scores.columns, name = 'KNN(SMOTE/Under)')\n",
    "\n",
    "smote_lr = pd.Series(data=[accuracy_score(y_test, lr_pred), recall_score(y_test, lr_pred),\n",
    "                              f1_score(y_test, lr_pred ,average='weighted')], index=binary_scores.columns, name = 'LR(SMOTE/Under)')\n",
    "\n",
    "smote_rf = pd.Series(data=[accuracy_score(y_test, rf_pred), recall_score(y_test, rf_pred),\n",
    "                              f1_score(y_test, rf_pred ,average='weighted')], index=binary_scores.columns, name = 'RF(LR(SMOTE/Under))')\n",
    "\n",
    "smote_et = pd.Series(data=[accuracy_score(y_test, et_pred), recall_score(y_test, et_pred),\n",
    "                              f1_score(y_test, et_pred ,average='weighted')], index=binary_scores.columns, name = 'ET(LR(SMOTE/Under))')\n",
    "\n",
    "binary_scores = binary_scores.append([smote_knn, smote_lr, smote_rf, smote_et])\n",
    "\n",
    "binary_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETATION:** It looks like my best models use a combination of oversampling using SMOTE and Random Under Sampling.<br>\n",
    "Specifically, Extra Trees using this combination was the best predictor of our minority class (highest recall score).<br>\n",
    "*Reminder Baseline:<br> \n",
    "0 claims = 92%<br>\n",
    "At least 1 claim = 7.9%<br>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at training/testing scores of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN(SMOTE/UNDER) Training Results:\n",
      "0.8054363376251789\n",
      "0.6738197424892703\n",
      "\n",
      "RF(SMOTE/UNDER) Testing Results:\n",
      "0.7665615141955836\n",
      "0.37623762376237624\n"
     ]
    }
   ],
   "source": [
    "print('KNN(SMOTE/UNDER) Training Results:')\n",
    "print(knn.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, knn.predict(X_sm_und)))\n",
    "\n",
    "print('\\nRF(SMOTE/UNDER) Testing Results:')\n",
    "print(knn.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, knn.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR(SMOTE/UNDER) Training Results:\n",
      "0.7467811158798283\n",
      "0.48068669527896996\n",
      "\n",
      "LR(SMOTE/UNDER) Testing Results:\n",
      "0.8036277602523659\n",
      "0.27722772277227725\n"
     ]
    }
   ],
   "source": [
    "print('LR(SMOTE/UNDER) Training Results:')\n",
    "print(lr.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, lr.predict(X_sm_und)))\n",
    "\n",
    "print('\\nLR(SMOTE/UNDER) Testing Results:')\n",
    "print(lr.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, lr.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF(SMOTE/UNDER) Training Results:\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "RF(SMOTE/UNDER) Testing Results:\n",
      "0.8982649842271293\n",
      "0.42574257425742573\n"
     ]
    }
   ],
   "source": [
    "print('RF(SMOTE/UNDER) Training Results:')\n",
    "print(rf.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, rf.predict(X_sm_und)))\n",
    "\n",
    "print('\\nRF(SMOTE/UNDER) Testing Results:')\n",
    "print(rf.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, rf.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET(SMOTE/UNDER) FIRST Training Results:\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "ET(SMOTE/UNDER) FIRST Testing Results:\n",
      "0.8659305993690851\n",
      "0.37623762376237624\n"
     ]
    }
   ],
   "source": [
    "et1_training_score = et.score(X_sm_und, y_sm_und)\n",
    "et1_recall_training_score = recall_score(y_sm_und, et.predict(X_sm_und))\n",
    "\n",
    "et1_testing_score = et.score(X_test_sc, y_test)\n",
    "et1_recall_testing_score = recall_score(y_test, et.predict(X_test_sc)) \n",
    "\n",
    "print('ET(SMOTE/UNDER) FIRST Training Results:')\n",
    "print(et1_training_score)\n",
    "print(et1_recall_training_score)\n",
    "\n",
    "print('\\nET(SMOTE/UNDER) FIRST Testing Results:')\n",
    "print(et1_testing_score)\n",
    "print(et1_recall_testing_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.predict(X_test_sc)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.predict(X_test_sc)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73, 0.27],\n",
       "       [0.68, 0.32],\n",
       "       [0.98, 0.02],\n",
       "       [1.  , 0.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.72, 0.28],\n",
       "       [1.  , 0.  ],\n",
       "       [0.89, 0.11],\n",
       "       [0.75, 0.25],\n",
       "       [0.96, 0.04],\n",
       "       [0.93, 0.07],\n",
       "       [0.94, 0.06],\n",
       "       [0.73, 0.27],\n",
       "       [0.81, 0.19],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.93, 0.07],\n",
       "       [0.35, 0.65],\n",
       "       [0.66, 0.34],\n",
       "       [0.92, 0.08],\n",
       "       [0.79, 0.21],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.71, 0.29],\n",
       "       [0.96, 0.04],\n",
       "       [0.02, 0.98],\n",
       "       [0.91, 0.09],\n",
       "       [0.98, 0.02],\n",
       "       [0.74, 0.26],\n",
       "       [0.64, 0.36],\n",
       "       [0.91, 0.09],\n",
       "       [0.88, 0.12],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.72, 0.28],\n",
       "       [0.52, 0.48],\n",
       "       [0.94, 0.06],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.73, 0.27],\n",
       "       [0.58, 0.42],\n",
       "       [0.92, 0.08],\n",
       "       [0.63, 0.37],\n",
       "       [0.84, 0.16],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.93, 0.07],\n",
       "       [0.93, 0.07],\n",
       "       [0.95, 0.05],\n",
       "       [0.71, 0.29],\n",
       "       [0.82, 0.18],\n",
       "       [0.96, 0.04]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.predict_proba(X_test_sc)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN(plain)</th>\n",
       "      <td>0.911672</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.892369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(plain)</th>\n",
       "      <td>0.919558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(plain)</th>\n",
       "      <td>0.934543</td>\n",
       "      <td>0.227723</td>\n",
       "      <td>0.917014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(plain)</th>\n",
       "      <td>0.926656</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.911725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN(oversample)</th>\n",
       "      <td>0.864353</td>\n",
       "      <td>0.346535</td>\n",
       "      <td>0.874381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(oversample)</th>\n",
       "      <td>0.897476</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.877101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(oversample)</th>\n",
       "      <td>0.932965</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.917971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(oversample)</th>\n",
       "      <td>0.925868</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.911837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN(SMOTE/Under)</th>\n",
       "      <td>0.766562</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.810732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(SMOTE/Under)</th>\n",
       "      <td>0.803628</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.832253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(LR(SMOTE/Under))</th>\n",
       "      <td>0.898265</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.901056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(LR(SMOTE/Under))</th>\n",
       "      <td>0.865931</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.876633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy    Recall  Weighted F1 Score\n",
       "KNN(plain)           0.911672  0.128713           0.892369\n",
       "LR(plain)            0.919558  0.000000           0.881779\n",
       "RF(plain)            0.934543  0.227723           0.917014\n",
       "ET(plain)            0.926656  0.237624           0.911725\n",
       "KNN(oversample)      0.864353  0.346535           0.874381\n",
       "LR(oversample)       0.897476  0.059406           0.877101\n",
       "RF(oversample)       0.932965  0.257426           0.917971\n",
       "ET(oversample)       0.925868  0.247525           0.911837\n",
       "KNN(SMOTE/Under)     0.766562  0.376238           0.810732\n",
       "LR(SMOTE/Under)      0.803628  0.277228           0.832253\n",
       "RF(LR(SMOTE/Under))  0.898265  0.425743           0.901056\n",
       "ET(LR(SMOTE/Under))  0.865931  0.376238           0.876633"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Regularization and SMOTE/Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I hadn't included any regularization in my logistic regression model and wanted to see how it did.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlychamberlain/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRCV(SMOTE/UNDER) Training Results:\n",
      "0.7453505007153076\n",
      "0.45493562231759654\n",
      "\n",
      "LRCV(SMOTE/UNDER) Testing Results:\n",
      "0.8225552050473186\n",
      "0.26732673267326734\n"
     ]
    }
   ],
   "source": [
    "logreg_cv = LogisticRegressionCV(Cs=10, cv=5, penalty=\"l1\", solver=\"liblinear\", random_state=42)\n",
    "logreg_cv.fit(X_sm_und, y_sm_und)\n",
    "logreg_cv_pred = logreg_cv.predict(X_test_sc)\n",
    "\n",
    "print('LRCV(SMOTE/UNDER) Training Results:')\n",
    "print(logreg_cv.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, logreg_cv.predict(X_sm_und)))\n",
    "\n",
    "print('\\nLRCV(SMOTE/UNDER) Testing Results:')\n",
    "print(logreg_cv.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, logreg_cv.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN(plain)</th>\n",
       "      <td>0.911672</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.892369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(plain)</th>\n",
       "      <td>0.919558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(plain)</th>\n",
       "      <td>0.934543</td>\n",
       "      <td>0.227723</td>\n",
       "      <td>0.917014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(plain)</th>\n",
       "      <td>0.926656</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.911725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN(oversample)</th>\n",
       "      <td>0.864353</td>\n",
       "      <td>0.346535</td>\n",
       "      <td>0.874381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(oversample)</th>\n",
       "      <td>0.897476</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.877101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(oversample)</th>\n",
       "      <td>0.932965</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.917971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(oversample)</th>\n",
       "      <td>0.925868</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.911837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN(SMOTE/Under)</th>\n",
       "      <td>0.766562</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.810732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(SMOTE/Under)</th>\n",
       "      <td>0.803628</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.832253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(LR(SMOTE/Under))</th>\n",
       "      <td>0.898265</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.901056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(LR(SMOTE/Under))</th>\n",
       "      <td>0.865931</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.876633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRCV(SMOTE/Under)</th>\n",
       "      <td>0.822555</td>\n",
       "      <td>0.267327</td>\n",
       "      <td>0.844014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy    Recall  Weighted F1 Score\n",
       "KNN(plain)           0.911672  0.128713           0.892369\n",
       "LR(plain)            0.919558  0.000000           0.881779\n",
       "RF(plain)            0.934543  0.227723           0.917014\n",
       "ET(plain)            0.926656  0.237624           0.911725\n",
       "KNN(oversample)      0.864353  0.346535           0.874381\n",
       "LR(oversample)       0.897476  0.059406           0.877101\n",
       "RF(oversample)       0.932965  0.257426           0.917971\n",
       "ET(oversample)       0.925868  0.247525           0.911837\n",
       "KNN(SMOTE/Under)     0.766562  0.376238           0.810732\n",
       "LR(SMOTE/Under)      0.803628  0.277228           0.832253\n",
       "RF(LR(SMOTE/Under))  0.898265  0.425743           0.901056\n",
       "ET(LR(SMOTE/Under))  0.865931  0.376238           0.876633\n",
       "LRCV(SMOTE/Under)    0.822555  0.267327           0.844014"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding results to the results table\n",
    "logregcv_et = pd.Series(data=[accuracy_score(y_test, logreg_cv_pred), recall_score(y_test, logreg_cv_pred),\n",
    "                              f1_score(y_test, logreg_cv_pred ,average='weighted')], index=binary_scores.columns, name = 'LRCV(SMOTE/Under)')\n",
    "\n",
    "binary_scores = binary_scores.append([logregcv_et])\n",
    "\n",
    "binary_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at feature importance from best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ref: https://towardsdatascience.com/interpreting-random-forest-and-other-black-box-models-like-xgboost-80f9cc4a3c38\n",
    "\n",
    "# knn_smote_under_feature_imp = pd.DataFrame({'Variable':X.columns,\n",
    "#               'Importance':et.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# knn_smote_under_feature_imp[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>policy_length</td>\n",
       "      <td>0.088564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.052842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Length</td>\n",
       "      <td>0.052153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hull Limit</td>\n",
       "      <td>0.051532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Year Built</td>\n",
       "      <td>0.050719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Years Exp.</td>\n",
       "      <td>0.047541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New/Renl/Endt/Canc/Flat_new</td>\n",
       "      <td>0.028803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Occupation_other</td>\n",
       "      <td>0.021501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Married yes/no_yes</td>\n",
       "      <td>0.019870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># Engines</td>\n",
       "      <td>0.019605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Married yes/no_not reported</td>\n",
       "      <td>0.019598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Occupation_not reported</td>\n",
       "      <td>0.018847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mooring County_other</td>\n",
       "      <td>0.018552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>New/Renl/Endt/Canc/Flat_renl</td>\n",
       "      <td>0.018257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Builder_other</td>\n",
       "      <td>0.018159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Mooring County_monroe</td>\n",
       "      <td>0.016436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Occupation_retired</td>\n",
       "      <td>0.016033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Hull Type_motoryacht</td>\n",
       "      <td>0.015566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Hull Type_monohull sail</td>\n",
       "      <td>0.014871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Hull Type_multihull sail</td>\n",
       "      <td>0.013402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Mooring County_caribbean</td>\n",
       "      <td>0.012569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New/Renl/Endt/Canc/Flat_endt</td>\n",
       "      <td>0.012328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Mooring County_pinellas</td>\n",
       "      <td>0.011218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Mooring County_broward</td>\n",
       "      <td>0.010784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Mooring County_san diego</td>\n",
       "      <td>0.010718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Mooring County_miami-dade</td>\n",
       "      <td>0.010525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Mooring County_bcs</td>\n",
       "      <td>0.010136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Hull Type_sportfisher</td>\n",
       "      <td>0.009996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Hull Type_trawler</td>\n",
       "      <td>0.009232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Mooring County_orange</td>\n",
       "      <td>0.008969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Variable  Importance\n",
       "6                   policy_length    0.088564\n",
       "5                             Age    0.052842\n",
       "2                          Length    0.052153\n",
       "3                      Hull Limit    0.051532\n",
       "1                      Year Built    0.050719\n",
       "0                      Years Exp.    0.047541\n",
       "9     New/Renl/Endt/Canc/Flat_new    0.028803\n",
       "24               Occupation_other    0.021501\n",
       "12             Married yes/no_yes    0.019870\n",
       "4                       # Engines    0.019605\n",
       "11    Married yes/no_not reported    0.019598\n",
       "23        Occupation_not reported    0.018847\n",
       "99           Mooring County_other    0.018552\n",
       "10   New/Renl/Endt/Canc/Flat_renl    0.018257\n",
       "46                  Builder_other    0.018159\n",
       "94          Mooring County_monroe    0.016436\n",
       "29             Occupation_retired    0.016033\n",
       "59           Hull Type_motoryacht    0.015566\n",
       "58        Hull Type_monohull sail    0.014871\n",
       "61       Hull Type_multihull sail    0.013402\n",
       "74       Mooring County_caribbean    0.012569\n",
       "7    New/Renl/Endt/Canc/Flat_endt    0.012328\n",
       "102       Mooring County_pinellas    0.011218\n",
       "72         Mooring County_broward    0.010784\n",
       "103      Mooring County_san diego    0.010718\n",
       "93      Mooring County_miami-dade    0.010525\n",
       "70             Mooring County_bcs    0.010136\n",
       "63          Hull Type_sportfisher    0.009996\n",
       "64              Hull Type_trawler    0.009232\n",
       "98          Mooring County_orange    0.008969"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ref: https://towardsdatascience.com/interpreting-random-forest-and-other-black-box-models-like-xgboost-80f9cc4a3c38\n",
    "\n",
    "et_smote_under_feature_imp = pd.DataFrame({'Variable':X.columns,\n",
    "              'Importance':et.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "\n",
    "et_smote_under_feature_imp[:30]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to feature importance of second best model\n",
    "\n",
    "rf_smote_under_feature_imp = pd.DataFrame({'Variable':X.columns,\n",
    "              'Importance':rf.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "\n",
    "top_30 = rf_smote_under_feature_imp[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only top 30 important features to use in an updated model \n",
    "post_rf_model_features = [x for x in top_30['Variable']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo models again using only top 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accuracy, Recall, Weighted F1 Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_scores2 = pd.DataFrame(columns=['Accuracy', 'Recall','Weighted F1 Score'])\n",
    "binary_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined[post_rf_model_features]\n",
    "y = combined['binary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.1, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X_sm_und, y_sm_und = pipeline.fit_resample(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_sm_und, y_sm_und)\n",
    "knn_pred = knn.predict(X_test_sc)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_sm_und, y_sm_und)\n",
    "lr_pred = lr.predict(X_test_sc)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf.fit(X_sm_und, y_sm_und)\n",
    "rf_pred = rf.predict(X_test_sc)\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=100,random_state=42)\n",
    "et.fit(X_sm_und, y_sm_und)\n",
    "et_pred = et.predict(X_test_sc)\n",
    "\n",
    "logreg_cv = LogisticRegressionCV(Cs=10, cv=5, penalty=\"l1\", solver=\"liblinear\", random_state=42)\n",
    "logreg_cv.fit(X_sm_und, y_sm_und)\n",
    "logreg_cv_pred = logreg_cv.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New_Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN(SMOTE/Under)</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.800925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(SMOTE/Under)</th>\n",
       "      <td>0.868297</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.872423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(SMOTE/Under))</th>\n",
       "      <td>0.884858</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.892301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(SMOTE/Under))</th>\n",
       "      <td>0.854101</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>0.869063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOGREG(SMOTE/Under))</th>\n",
       "      <td>0.902997</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.885967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy    Recall  Weighted F1 Score\n",
       "KNN(SMOTE/Under)      0.750000  0.445545           0.800925\n",
       "LR(SMOTE/Under)       0.868297  0.247525           0.872423\n",
       "RF(SMOTE/Under))      0.884858  0.445545           0.892301\n",
       "ET(SMOTE/Under))      0.854101  0.386139           0.869063\n",
       "LOGREG(SMOTE/Under))  0.902997  0.118812           0.885967"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_knn = pd.Series(data=[accuracy_score(y_test, knn_pred), recall_score(y_test, knn_pred),\n",
    "                              f1_score(y_test, knn_pred ,average='weighted')], index=binary_scores2.columns, name = 'KNN(SMOTE/Under)')\n",
    "\n",
    "smote_lr = pd.Series(data=[accuracy_score(y_test, lr_pred), recall_score(y_test, lr_pred),\n",
    "                              f1_score(y_test, lr_pred ,average='weighted')], index=binary_scores2.columns, name = 'LR(SMOTE/Under)')\n",
    "\n",
    "smote_rf = pd.Series(data=[accuracy_score(y_test, rf_pred), recall_score(y_test, rf_pred),\n",
    "                              f1_score(y_test, rf_pred ,average='weighted')], index=binary_scores2.columns, name = 'RF(SMOTE/Under))')\n",
    "\n",
    "smote_et = pd.Series(data=[accuracy_score(y_test, et_pred), recall_score(y_test, et_pred),\n",
    "                              f1_score(y_test, et_pred ,average='weighted')], index=binary_scores2.columns, name = 'ET(SMOTE/Under))')\n",
    "\n",
    "smote_logreg_cv = pd.Series(data=[accuracy_score(y_test, logreg_cv_pred), recall_score(y_test, logreg_cv_pred),\n",
    "                              f1_score(y_test, logreg_cv_pred ,average='weighted')], index=binary_scores2.columns, name = 'LOGREG(SMOTE/Under))')\n",
    "\n",
    "binary_scores2 = binary_scores2.append([smote_knn, smote_lr, smote_rf, smote_et, smote_logreg_cv])\n",
    "\n",
    "print('New_Scores')\n",
    "binary_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old_Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN(SMOTE/Under)</th>\n",
       "      <td>0.766562</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.810732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR(SMOTE/Under)</th>\n",
       "      <td>0.803628</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.832253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF(LR(SMOTE/Under))</th>\n",
       "      <td>0.898265</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.901056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET(LR(SMOTE/Under))</th>\n",
       "      <td>0.865931</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.876633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRCV(SMOTE/Under)</th>\n",
       "      <td>0.822555</td>\n",
       "      <td>0.267327</td>\n",
       "      <td>0.844014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy    Recall  Weighted F1 Score\n",
       "KNN(SMOTE/Under)     0.766562  0.376238           0.810732\n",
       "LR(SMOTE/Under)      0.803628  0.277228           0.832253\n",
       "RF(LR(SMOTE/Under))  0.898265  0.425743           0.901056\n",
       "ET(LR(SMOTE/Under))  0.865931  0.376238           0.876633\n",
       "LRCV(SMOTE/Under)    0.822555  0.267327           0.844014"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Old_Scores')\n",
    "binary_scores[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETATION:** Scores improved after using only the top 30 most important features from the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN(SMOTE/UNDER) SECOND Training Results:\n",
      "0.7982832618025751\n",
      "0.6781115879828327\n",
      "\n",
      "RF(SMOTE/UNDER) SECOND Testing Results:\n",
      "0.75\n",
      "0.44554455445544555\n"
     ]
    }
   ],
   "source": [
    "print('KNN(SMOTE/UNDER) SECOND Training Results:')\n",
    "print(knn.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, knn.predict(X_sm_und)))\n",
    "\n",
    "print('\\nRF(SMOTE/UNDER) SECOND Testing Results:')\n",
    "print(knn.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, knn.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR(SMOTE/UNDER) SECOND Training Results:\n",
      "0.6859799713876967\n",
      "0.2532188841201717\n",
      "\n",
      "LR(SMOTE/UNDER) SECOND Testing Results:\n",
      "0.8682965299684543\n",
      "0.24752475247524752\n"
     ]
    }
   ],
   "source": [
    "print('LR(SMOTE/UNDER) SECOND Training Results:')\n",
    "print(lr.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, lr.predict(X_sm_und)))\n",
    "\n",
    "print('\\nLR(SMOTE/UNDER) SECOND Testing Results:')\n",
    "print(lr.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, lr.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF(SMOTE/UNDER) SECOND Training Results:\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "RF(SMOTE/UNDER) SECOND Testing Results:\n",
      "0.8848580441640379\n",
      "0.44554455445544555\n"
     ]
    }
   ],
   "source": [
    "print('RF(SMOTE/UNDER) SECOND Training Results:')\n",
    "print(rf.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, rf.predict(X_sm_und)))\n",
    "\n",
    "print('\\nRF(SMOTE/UNDER) SECOND Testing Results:')\n",
    "print(rf.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, rf.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET(SMOTE/UNDER) SECOND Training Results:\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "ET(SMOTE/UNDER) SECOND Testing Results:\n",
      "0.8541009463722398\n",
      "0.38613861386138615\n"
     ]
    }
   ],
   "source": [
    "print('ET(SMOTE/UNDER) SECOND Training Results:')\n",
    "print(et.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, et.predict(X_sm_und)))\n",
    "\n",
    "print('\\nET(SMOTE/UNDER) SECOND Testing Results:')\n",
    "print(et.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, et.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Gridsearch over KNN to fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref for gridsearching for recall score: https://stackoverflow.com/questions/49035011/get-precison-model-through-gridsearchcv-for-recall-optimization\n",
    "knn_params = {\n",
    "    'n_neighbors':range(2, 5),\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn_gridsearch = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, \n",
    "                              verbose=1, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "knn_gridsearch.fit(X_sm_und, y_sm_und);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5344314802104781\n",
      "{'metric': 'euclidean', 'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "print(knn_gridsearch.best_score_)\n",
    "print(knn_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Gridsearch Training Results:\n",
      "0.8426323319027181\n",
      "0.7682403433476395\n",
      "\n",
      "KNN Gridsearch Testing Results:\n",
      "0.748422712933754\n",
      "0.4752475247524752\n"
     ]
    }
   ],
   "source": [
    "print('KNN Gridsearch Training Results:')\n",
    "print(accuracy_score(y_sm_und, knn_gridsearch.predict(X_sm_und)))\n",
    "print(knn_gridsearch.score(X_sm_und, y_sm_und))\n",
    "\n",
    "print('\\nKNN Gridsearch Testing Results:')\n",
    "print(accuracy_score(y_test, knn_gridsearch.predict(X_test_sc)))\n",
    "print(knn_gridsearch.score(X_test_sc, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "knn_model = knn_gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch over RF to fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:   16.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4379775795012583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 50}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [50,75,100],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "rf_gs = GridSearchCV(RandomForestClassifier(), param_grid=rf_params, cv=5, \n",
    "                     verbose= 1, scoring= 'recall')\n",
    "rf_gs.fit(X_sm_und, y_sm_und)\n",
    "print(rf_gs.best_score_)\n",
    "rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Gridsearch Training Results:\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "RF Gridsearch Testing Results:\n",
      "0.8777602523659306\n",
      "0.36633663366336633\n"
     ]
    }
   ],
   "source": [
    "print('RF Gridsearch Training Results:')\n",
    "print(accuracy_score(y_sm_und, rf_gs.predict(X_sm_und)))\n",
    "print(rf_gs.score(X_sm_und, y_sm_und))\n",
    "\n",
    "\n",
    "print('\\nRF Gridsearch Testing Results:')\n",
    "print(accuracy_score(y_test, rf_gs.predict(X_test_sc)))\n",
    "print(rf_gs.score(X_test_sc, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch over ET to fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "et_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "et_gs = GridSearchCV(ExtraTreesClassifier(), param_grid=et_params, cv=5, \n",
    "                     verbose= 1, scoring= 'recall')\n",
    "et_gs.fit(X_sm_und, y_sm_und)\n",
    "print(et_gs.best_score_)\n",
    "et_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ET Gridsearch Training Results:')\n",
    "print(accuracy_score(y_sm_und, et_gs.predict(X_sm_und)))\n",
    "print(et_gs.score(X_sm_und, y_sm_und))\n",
    "\n",
    "\n",
    "print('\\nET Gridsearch Testing Results:')\n",
    "print(accuracy_score(y_test, et_gs.predict(X_test_sc)))\n",
    "print(et_gs.score(X_test_sc, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "\n",
    "# results = permutation_importance(knn_gridsearch, X_sm_und, y_sm_und, scoring='recall')\n",
    "# # get importance\n",
    "# importance = results.importances_mean\n",
    "# # summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "#     print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# # # plot feature importance\n",
    "# # pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# # pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reminder of best params for RF\n",
    "# rf_gs.best_params_\n",
    "\n",
    "# # Instantiate model w/ best params in order to pull the feature importances\n",
    "# new_rf = RandomForestClassifier(max_depth=None, n_estimators=75,random_state=42)\n",
    "# new_rf.fit(X_sm_und, y_sm_und)\n",
    "# new_rf_pred = new_rf.predict(X_test_sc)\n",
    "\n",
    "# new_rf_feature_imp = pd.DataFrame({'Variable':X.columns,\n",
    "#               'Importance':new_rf.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# new_rf_feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting best model: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of best params for RF\n",
    "rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rf = RandomForestClassifier(max_depth=None, n_estimators=50,random_state=42)\n",
    "best_model_rf.fit(X_sm_und, y_sm_und)\n",
    "bm_rf_pred = best_model_rf.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model KNN scores\n",
    "print('Best Model, RF: Training Results:')\n",
    "print(best_model_rf.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, best_model_rf.predict(X_sm_und)))\n",
    "\n",
    "print('\\nBest Model, RF: Testing Results:')\n",
    "print(best_model_rf.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, best_model_rf.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETATION:** Model is overfit will try to play around with the feature selection below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_probs = best_model_rf.predict_proba(X_test_sc)\n",
    "bm_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_feature_imp = pd.DataFrame({'Variable':X.columns,\n",
    "              'Importance':best_model_rf.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "\n",
    "best_rf_feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Test best model with 'Policy Length' and 'New/Renl/Endt/Canc/Flat' removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removals = [col for col in combined if col.startswith('New/Renl/Endt/Canc/Flat')]\n",
    "removals.append('policy_length')\n",
    "removals.append('num_claims')\n",
    "removals.append('binary')\n",
    "removals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined.drop(columns=removals)\n",
    "y = combined['binary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.1,random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5,random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X_sm_und, y_sm_und = pipeline.fit_resample(X_train_sc, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=None, n_estimators=50,random_state=42)\n",
    "rf.fit(X_sm_und, y_sm_und)\n",
    "rf_pred = rf.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New RF scores\n",
    "print('New RF: Training Results:')\n",
    "print(rf.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, rf.predict(X_sm_und)))\n",
    "\n",
    "print('\\nBest Model, RF: Testing Results:')\n",
    "print(rf.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, rf.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_imp = pd.DataFrame({'Variable':X.columns,\n",
    "              'Importance':rf.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "\n",
    "rf_feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it after keeping only the top 30 features from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 30 rows of the important features\n",
    "new_top_30 = rf_smote_under_feature_imp[:30]\n",
    "\n",
    "# Make a list of the column names of the top 30\n",
    "new_top_30_features = [x for x in new_top_30['Variable']]\n",
    "\n",
    "new_top_30_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of columns we don't want in the final list of features\n",
    "# drops = ['policy_length','New/Renl/Endt/Canc/Flat_new','New/Renl/Endt/Canc/Flat_renl','New/Renl/Endt/Canc/Flat_endt']\n",
    "\n",
    "# # Create a new list of features we will use for X\n",
    "# final_features = [x for x in new_top_30 if x not in drops]\n",
    "\n",
    "# final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined[new_top_30_features]\n",
    "y = combined['binary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.1,random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5,random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X_sm_und, y_sm_und = pipeline.fit_resample(X_train_sc, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=None, n_estimators=50,random_state=42)\n",
    "rf.fit(X_sm_und, y_sm_und)\n",
    "rf_pred = rf.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New KNN scores\n",
    "print('Final RF: Training Results:')\n",
    "print(rf.score(X_sm_und, y_sm_und))\n",
    "print(recall_score(y_sm_und, rf.predict(X_sm_und)))\n",
    "\n",
    "print('\\nFinal RF: Testing Results:')\n",
    "print(rf.score(X_test_sc, y_test))\n",
    "print(recall_score(y_test, rf.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf_feature_imp = pd.DataFrame({'Variable':X.columns,\n",
    "              'Importance':rf.feature_importances_}).sort_values('Importance', ascending=False)\n",
    "\n",
    "final_rf_feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETATION:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
